{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "str expected, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/A200154990/lang/CSK/CSKBOT/dockling.ipynb Cell 1\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/A200154990/lang/CSK/CSKBOT/dockling.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mdotenv\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m load_dotenv\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/A200154990/lang/CSK/CSKBOT/dockling.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m load_dotenv()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/A200154990/lang/CSK/CSKBOT/dockling.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m os\u001b[39m.\u001b[39;49menviron[\u001b[39m'\u001b[39;49m\u001b[39mOPENAI_API_KEY\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m\"\u001b[39m\u001b[39mOPENAI_API_KEY\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/A200154990/lang/CSK/CSKBOT/dockling.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mTOKENIZERS_PARALLELISM\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfalse\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/os.py:685\u001b[0m, in \u001b[0;36m_Environ.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m__setitem__\u001b[39m(\u001b[39mself\u001b[39m, key, value):\n\u001b[1;32m    684\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencodekey(key)\n\u001b[0;32m--> 685\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencodevalue(value)\n\u001b[1;32m    686\u001b[0m     putenv(key, value)\n\u001b[1;32m    687\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data[key] \u001b[39m=\u001b[39m value\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/os.py:757\u001b[0m, in \u001b[0;36m_createenviron.<locals>.encode\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mencode\u001b[39m(value):\n\u001b[1;32m    756\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 757\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mstr expected, not \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mtype\u001b[39m(value)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    758\u001b[0m     \u001b[39mreturn\u001b[39;00m value\u001b[39m.\u001b[39mencode(encoding, \u001b[39m'\u001b[39m\u001b[39msurrogateescape\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: str expected, not NoneType"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tempfile import mkdtemp\n",
    "from warnings import filterwarnings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/A200154990/Langchain/CSKBOT'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751518161.267915 3806843 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (0.12.44)\n",
      "Requirement already satisfied: openai in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (1.91.0)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5,>=0.4.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index) (0.4.11)\n",
      "Requirement already satisfied: llama-index-cli<0.5,>=0.4.2 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index) (0.4.3)\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.44 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index) (0.12.44)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4,>=0.3.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index) (0.7.7)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.5,>=0.4.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index) (0.4.7)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.6,>=0.5.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index) (0.5.1)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4,>=0.3.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index) (0.3.2)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4,>=0.3.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5,>=0.4.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index) (0.4.9)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from openai) (2.11.5)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (3.11.10)\n",
      "Requirement already satisfied: aiosqlite in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (2.1.2)\n",
      "Requirement already satisfied: dataclasses-json in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (2024.3.1)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (1.0.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (3.4.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (2.2.6)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.44->llama-index) (2.0.36)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (1.17.1)\n",
      "Requirement already satisfied: llama-cloud==0.1.26 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.26)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pandas<2.3.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.2.3)\n",
      "Requirement already satisfied: pypdf<6,>=5.1.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (5.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.34)\n",
      "Requirement already satisfied: click in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (1.18.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (4.0.3)\n",
      "Requirement already satisfied: griffe in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama-index) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama-index) (3.1.5)\n",
      "Requirement already satisfied: platformdirs in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama-index) (4.3.8)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.6)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.44->llama-index) (0.2.0)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.32 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.34)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.44->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.44->llama-index) (2.4.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.44->llama-index) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.44->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.44->llama-index) (3.24.2)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from llama-cloud-services>=0.6.32->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.44->llama-index) (23.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (1.16.0)\n",
      "Requirement already satisfied: colorama>=0.4 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama-index) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama-index) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --progress-bar off llama-index-readers-docling \\\n",
    "llama-index-node-parser-docling llama-index-embeddings-huggingface \\\n",
    "llama-index-llms-huggingface-api llama-index-vector-stores-milvus \\\n",
    "llama-index-readers-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.docling import DoclingReader\n",
    "from llama_index.core import download_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Internal IT Administration: Questions and Answers\n",
      "\n",
      "This document provides a comprehensive list of internal IT administration questions across software, hardware, networking, and VPN domains, with detailed answers. The content is structured for easy indexing and retrieval, and includes various formats (paragraphs, lists, tables, JSON) to challenge a RAG pipeline.\n",
      "\n",
      "## Software Administration\n",
      "\n",
      "- Question: How do you schedule and manage updates for software applications across multiple enterprise workstations? 1.\n",
      "\n",
      "Answer: Use centralized   patch   management   tools   to   automate   deployment.   For   example, configure Windows Server Update Services (WSUS) or System Center Configuration Manager (SCCM) for Windows machines, and tools like Ansible, Puppet, or Chef for Linux environments. Create deployment groups (e.g., by department or operating system) and schedule updates during   off-peak   hours   to   minimize   disruption.   Always   test   updates   in   a   staging   or   pilot environment before full rollout. Maintain an inventory of installed software to track which applications need updating.\n",
      "\n",
      "- Question: What are the best practices for testing software before deployment in an enterprise environment? 2.\n",
      "\n",
      "Answer: Effective testing includes multiple stages:\n",
      "\n",
      "- Staging Environment: Use a test network that mirrors production, including hardware and software configurations, to catch compatibility issues. 3.\n",
      "- Automated Testing: Implement continuous integration/continuous deployment (CI/CD) pipelines with automated unit and integration tests. 4.\n",
      "- User Acceptance Testing (UAT): Engage a group of end users to try new features and provide feedback. 5.\n",
      "- Rollback Plan: Prepare a rollback procedure (backups, snapshots) in case the deployment causes issues. 6.\n",
      "- Documentation: Maintain   clear   documentation   of   test   results   and   update   procedures   for auditing. 7.\n",
      "- Question: How do you troubleshoot a program that fails to install on Windows due to a 8.\n",
      "- missing .NET Framework dependency? Answer: First, identify the missing dependency by checking installation logs or Windows Event Viewer for errors. Then:\n",
      "- Install Required .NET Version: Download and install the specific .NET Framework or .NET runtime required by the application. 9.\n",
      "- Enable Windows Features: Go to \"Turn Windows features on or off\" and enable the needed .NET components on Windows. 10.\n",
      "- Restart: Reboot the system after installing .NET. 11.\n",
      "\n",
      "- Re-run Installer: Run the application installer again, preferably as Administrator . 12.\n",
      "- Verify Compatibility: Ensure the program supports your OS version; use compatibility mode if 13.\n",
      "- needed. If the issue persists, check for a Microsoft support article or vendor documentation for specific fixes.\n",
      "- Question: Describe the process of deploying a new enterprise application to multiple users. Answer: Deployment typically follows these steps: 14.\n",
      "- Planning: Define requirements, target user groups, and dependencies. 15.\n",
      "- Packaging: Create the application installer or deployment package (MSI, EXE, or script). 16.\n",
      "- Testing: Install on test machines and resolve any compatibility issues. 17.\n",
      "- Rollout: Use management tools (Group Policy, SCCM, Intune) to distribute the package to user workstations. 18.\n",
      "- Verification: Check logs and user feedback to confirm successful installation. 19.\n",
      "- Documentation: Update records with version, installation date, and deployment scope. 20.\n",
      "- Support: Provide help for users if any issues arise post-deployment. 21.\n",
      "- Question: How is Group Policy used in a Windows domain environment? 22.\n",
      "- Answer: Group Policy Objects (GPOs) centrally configure settings for users and computers in\n",
      "- Active Directory. By linking GPOs to Organizational Units (OUs), administrators enforce policies like password rules, software restrictions, mapped drives, and security configurations. GPOs have both computer and user sections. Computer policies (e.g., firewall rules, updates) apply at system startup, while user policies (e.g., desktop settings, folder redirection) apply at logon. This ensures consistent configurations and simplifies administration across the domain.\n",
      "- Question: What is virtualization and how does it benefit an enterprise? Answer: Virtualization abstracts physical hardware into software-based virtual machines (VMs). 23.\n",
      "- Benefits include:\n",
      "- Resource Efficiency: Host multiple VMs on a single physical server , maximizing CPU and memory use. 24.\n",
      "- Flexibility: Quickly create, clone, or migrate VMs for testing or scaling services. 25.\n",
      "- Isolation: VMs are isolated from each other , improving security and stability (a VM crash doesn't affect others). 26.\n",
      "- Cost Savings: Reduce the number of physical servers, saving on hardware, power, and cooling. 27.\n",
      "- Backup &amp; Recovery: Use snapshots or templates for easy backups and rapid recovery. 28.\n",
      "- Legacy Support: Run outdated OS or applications in a VM while the host runs a modern OS. 29.\n",
      "- Question: How do you manage c\n"
     ]
    }
   ],
   "source": [
    "reader = DoclingReader()\n",
    "\n",
    "# Load the PDF file\n",
    "documents = reader.load_data(\"Internal.pdf\")\n",
    "\n",
    "# Display output\n",
    "for doc in documents:\n",
    "    print(doc.text[:5000])  # Print first 500 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "from llama_index.llms.openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"\"\n",
    "'''BAAI/bge-small-en-v1.5 - Beijing Academy of Artificial Intelligence (BAAI)\n",
    "Sentence Embedding Model / Text Embedding Model\n",
    "Specifically designed for English text.\n",
    "Based on E5 architecture, which itself is a modification of the MiniLM \n",
    "(or similar lightweight Transformer) architecture optimized for embedding tasks.\n",
    "~60 million parameters'''\n",
    "\n",
    "EMBED_MODEL = HuggingFaceEmbedding(\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "\n",
    "embed_dim = len(EMBED_MODEL.get_text_embedding(\"hi\"))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "from llama_index.readers.docling import DoclingReader\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE = 'Internal.pdf'\n",
    "#SOURCE = \"https://arxiv.org/pdf/2408.09869\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/milvus_lite/__init__.py:15: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-07-03 15:20:13,943 [DEBUG][_create_connection]: Created new connection using: 20ebdbc230994adb9ec652df066b91f4 (async_milvus_client.py:599)\n"
     ]
    }
   ],
   "source": [
    "reader = DoclingReader()\n",
    "node_parser = MarkdownNodeParser()\n",
    "MILVUS_URI = str(Path(mkdtemp())/ 'docling_ahtsham.db')\n",
    "vector_store = MilvusVectorStore(uri=MILVUS_URI,dim=embed_dim,overwrite=True)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=reader.load_data(SOURCE),\n",
    "    transformations=[node_parser],\n",
    "    storage_context=StorageContext.from_defaults(vector_store=vector_store),\n",
    "    embed_model=EMBED_MODEL,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['gpt-3.5-turbo','text-davinci-003']\n",
    "\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    max_tokens=512\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.8821814833687962 seconds as it raised APIConnectionError: Connection error..\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.11924063986921829 seconds as it raised APIConnectionError: Connection error..\n"
     ]
    },
    {
     "ename": "APIConnectionError",
     "evalue": "Connection error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLocalProtocolError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/httpx/_transports/default.py:72\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[1;32m    238\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[39mraise\u001b[39;00m exc \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[39m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mhandle_request(\n\u001b[1;32m    237\u001b[0m         pool_request\u001b[39m.\u001b[39;49mrequest\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    239\u001b[0m \u001b[39mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[39m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[39m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[39m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mhandle_request(request)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/httpcore/_sync/http11.py:86\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\n\u001b[1;32m     84\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msend_request_headers\u001b[39m\u001b[39m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     85\u001b[0m ) \u001b[39mas\u001b[39;00m trace:\n\u001b[0;32m---> 86\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request_headers(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     87\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\u001b[39m\"\u001b[39m\u001b[39msend_request_body\u001b[39m\u001b[39m\"\u001b[39m, logger, request, kwargs) \u001b[39mas\u001b[39;00m trace:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/httpcore/_sync/http11.py:144\u001b[0m, in \u001b[0;36mHTTP11Connection._send_request_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    142\u001b[0m timeout \u001b[39m=\u001b[39m timeouts\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mwrite\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 144\u001b[0m \u001b[39mwith\u001b[39;00m map_exceptions({h11\u001b[39m.\u001b[39mLocalProtocolError: LocalProtocolError}):\n\u001b[1;32m    145\u001b[0m     event \u001b[39m=\u001b[39m h11\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m    146\u001b[0m         method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    147\u001b[0m         target\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39murl\u001b[39m.\u001b[39mtarget,\n\u001b[1;32m    148\u001b[0m         headers\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mheaders,\n\u001b[1;32m    149\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen\u001b[39m.\u001b[39;49mthrow(typ, value, traceback)\n\u001b[1;32m    154\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[39mraise\u001b[39;00m to_exc(exc) \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mLocalProtocolError\u001b[0m: Illegal header value b'Bearer '",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mLocalProtocolError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/openai/_base_client.py:972\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 972\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49msend(\n\u001b[1;32m    973\u001b[0m         request,\n\u001b[1;32m    974\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_should_stream_response_body(request\u001b[39m=\u001b[39;49mrequest),\n\u001b[1;32m    975\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    976\u001b[0m     )\n\u001b[1;32m    977\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    924\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[1;32m    927\u001b[0m     request,\n\u001b[1;32m    928\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    929\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    930\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m    931\u001b[0m )\n\u001b[1;32m    932\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[1;32m    955\u001b[0m         request,\n\u001b[1;32m    956\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    957\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[1;32m    958\u001b[0m     )\n\u001b[1;32m    959\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[1;32m    992\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m   1029\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/httpx/_transports/default.py:235\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[0;32m--> 235\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m    236\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool\u001b[39m.\u001b[39mhandle_request(req)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen\u001b[39m.\u001b[39;49mthrow(typ, value, traceback)\n\u001b[1;32m    154\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/httpx/_transports/default.py:89\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m message \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(exc)\n\u001b[0;32m---> 89\u001b[0m \u001b[39mraise\u001b[39;00m mapped_exc(message) \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mLocalProtocolError\u001b[0m: Illegal header value b'Bearer '",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/Users/A200154990/lang/CSK/CSKBOT/dockling.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/A200154990/lang/CSK/CSKBOT/dockling.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m QUERY \u001b[39m=\u001b[39m  \u001b[39m'\u001b[39m\u001b[39mHow do you ensure software compliance (licensing) in an organization \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/A200154990/lang/CSK/CSKBOT/dockling.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m result \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mas_query_engine(llm\u001b[39m=\u001b[39;49mllm)\u001b[39m.\u001b[39;49mquery(QUERY)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/A200154990/lang/CSK/CSKBOT/dockling.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mQ: \u001b[39m\u001b[39m{\u001b[39;00mQUERY\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mA: \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mstrip()\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mSources:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/A200154990/lang/CSK/CSKBOT/dockling.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m display([(n\u001b[39m.\u001b[39mtext, n\u001b[39m.\u001b[39mmetadata) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m result\u001b[39m.\u001b[39msource_nodes])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/llama_index_instrumentation/dispatcher.py:319\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m             _logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to reset active_span_id: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    320\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, asyncio\u001b[39m.\u001b[39mFuture):\n\u001b[1;32m    321\u001b[0m         \u001b[39m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         new_future \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/llama_index/core/base/base_query_engine.py:52\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(str_or_query_bundle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     51\u001b[0m         str_or_query_bundle \u001b[39m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[0;32m---> 52\u001b[0m     query_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query(str_or_query_bundle)\n\u001b[1;32m     53\u001b[0m dispatcher\u001b[39m.\u001b[39mevent(\n\u001b[1;32m     54\u001b[0m     QueryEndEvent(query\u001b[39m=\u001b[39mstr_or_query_bundle, response\u001b[39m=\u001b[39mquery_result)\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[39mreturn\u001b[39;00m query_result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/llama_index_instrumentation/dispatcher.py:319\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m             _logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to reset active_span_id: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    320\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, asyncio\u001b[39m.\u001b[39mFuture):\n\u001b[1;32m    321\u001b[0m         \u001b[39m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         new_future \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/llama_index/core/query_engine/retriever_query_engine.py:183\u001b[0m, in \u001b[0;36mRetrieverQueryEngine._query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mevent(\n\u001b[1;32m    180\u001b[0m     CBEventType\u001b[39m.\u001b[39mQUERY, payload\u001b[39m=\u001b[39m{EventPayload\u001b[39m.\u001b[39mQUERY_STR: query_bundle\u001b[39m.\u001b[39mquery_str}\n\u001b[1;32m    181\u001b[0m ) \u001b[39mas\u001b[39;00m query_event:\n\u001b[1;32m    182\u001b[0m     nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretrieve(query_bundle)\n\u001b[0;32m--> 183\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_response_synthesizer\u001b[39m.\u001b[39;49msynthesize(\n\u001b[1;32m    184\u001b[0m         query\u001b[39m=\u001b[39;49mquery_bundle,\n\u001b[1;32m    185\u001b[0m         nodes\u001b[39m=\u001b[39;49mnodes,\n\u001b[1;32m    186\u001b[0m     )\n\u001b[1;32m    187\u001b[0m     query_event\u001b[39m.\u001b[39mon_end(payload\u001b[39m=\u001b[39m{EventPayload\u001b[39m.\u001b[39mRESPONSE: response})\n\u001b[1;32m    189\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/llama_index_instrumentation/dispatcher.py:319\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m             _logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to reset active_span_id: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    320\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, asyncio\u001b[39m.\u001b[39mFuture):\n\u001b[1;32m    321\u001b[0m         \u001b[39m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         new_future \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/llama_index/core/response_synthesizers/base.py:242\u001b[0m, in \u001b[0;36mBaseSynthesizer.synthesize\u001b[0;34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m     query \u001b[39m=\u001b[39m QueryBundle(query_str\u001b[39m=\u001b[39mquery)\n\u001b[1;32m    238\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_manager\u001b[39m.\u001b[39mevent(\n\u001b[1;32m    239\u001b[0m     CBEventType\u001b[39m.\u001b[39mSYNTHESIZE,\n\u001b[1;32m    240\u001b[0m     payload\u001b[39m=\u001b[39m{EventPayload\u001b[39m.\u001b[39mQUERY_STR: query\u001b[39m.\u001b[39mquery_str},\n\u001b[1;32m    241\u001b[0m ) \u001b[39mas\u001b[39;00m event:\n\u001b[0;32m--> 242\u001b[0m     response_str \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_response(\n\u001b[1;32m    243\u001b[0m         query_str\u001b[39m=\u001b[39;49mquery\u001b[39m.\u001b[39;49mquery_str,\n\u001b[1;32m    244\u001b[0m         text_chunks\u001b[39m=\u001b[39;49m[\n\u001b[1;32m    245\u001b[0m             n\u001b[39m.\u001b[39;49mnode\u001b[39m.\u001b[39;49mget_content(metadata_mode\u001b[39m=\u001b[39;49mMetadataMode\u001b[39m.\u001b[39;49mLLM) \u001b[39mfor\u001b[39;49;00m n \u001b[39min\u001b[39;49;00m nodes\n\u001b[1;32m    246\u001b[0m         ],\n\u001b[1;32m    247\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kwargs,\n\u001b[1;32m    248\u001b[0m     )\n\u001b[1;32m    250\u001b[0m     additional_source_nodes \u001b[39m=\u001b[39m additional_source_nodes \u001b[39mor\u001b[39;00m []\n\u001b[1;32m    251\u001b[0m     source_nodes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(nodes) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(additional_source_nodes)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/llama_index_instrumentation/dispatcher.py:319\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m             _logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to reset active_span_id: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    320\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, asyncio\u001b[39m.\u001b[39mFuture):\n\u001b[1;32m    321\u001b[0m         \u001b[39m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         new_future \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/llama_index/core/response_synthesizers/compact_and_refine.py:43\u001b[0m, in \u001b[0;36mCompactAndRefine.get_response\u001b[0;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m# use prompt helper to fix compact text_chunks under the prompt limitation\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m# TODO: This is a temporary fix - reason it's temporary is that\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39m# the refine template does not account for size of previous answer.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m new_texts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_compact_text_chunks(query_str, text_chunks)\n\u001b[0;32m---> 43\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mget_response(\n\u001b[1;32m     44\u001b[0m     query_str\u001b[39m=\u001b[39;49mquery_str,\n\u001b[1;32m     45\u001b[0m     text_chunks\u001b[39m=\u001b[39;49mnew_texts,\n\u001b[1;32m     46\u001b[0m     prev_response\u001b[39m=\u001b[39;49mprev_response,\n\u001b[1;32m     47\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kwargs,\n\u001b[1;32m     48\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/llama_index_instrumentation/dispatcher.py:319\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m             _logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to reset active_span_id: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    320\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, asyncio\u001b[39m.\u001b[39mFuture):\n\u001b[1;32m    321\u001b[0m         \u001b[39m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         new_future \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/llama_index/core/response_synthesizers/refine.py:179\u001b[0m, in \u001b[0;36mRefine.get_response\u001b[0;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mfor\u001b[39;00m text_chunk \u001b[39min\u001b[39;00m text_chunks:\n\u001b[1;32m    176\u001b[0m     \u001b[39mif\u001b[39;00m prev_response \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m         \u001b[39m# if this is the first chunk, and text chunk already\u001b[39;00m\n\u001b[1;32m    178\u001b[0m         \u001b[39m# is an answer, then return it\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_give_response_single(\n\u001b[1;32m    180\u001b[0m             query_str, text_chunk, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kwargs\n\u001b[1;32m    181\u001b[0m         )\n\u001b[1;32m    182\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m         \u001b[39m# refine response if possible\u001b[39;00m\n\u001b[1;32m    184\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_refine_response_single(\n\u001b[1;32m    185\u001b[0m             prev_response, query_str, text_chunk, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresponse_kwargs\n\u001b[1;32m    186\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/llama_index/core/response_synthesizers/refine.py:241\u001b[0m, in \u001b[0;36mRefine._give_response_single\u001b[0;34m(self, query_str, text_chunk, **response_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39mif\u001b[39;00m response \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_streaming:\n\u001b[1;32m    238\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m         structured_response \u001b[39m=\u001b[39m cast(\n\u001b[1;32m    240\u001b[0m             StructuredRefineResponse,\n\u001b[0;32m--> 241\u001b[0m             program(\n\u001b[1;32m    242\u001b[0m                 context_str\u001b[39m=\u001b[39;49mcur_text_chunk,\n\u001b[1;32m    243\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kwargs,\n\u001b[1;32m    244\u001b[0m             ),\n\u001b[1;32m    245\u001b[0m         )\n\u001b[1;32m    246\u001b[0m         query_satisfied \u001b[39m=\u001b[39m structured_response\u001b[39m.\u001b[39mquery_satisfied\n\u001b[1;32m    247\u001b[0m         \u001b[39mif\u001b[39;00m query_satisfied:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/llama_index_instrumentation/dispatcher.py:319\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m             _logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to reset active_span_id: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    320\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, asyncio\u001b[39m.\u001b[39mFuture):\n\u001b[1;32m    321\u001b[0m         \u001b[39m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         new_future \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/llama_index/core/response_synthesizers/refine.py:85\u001b[0m, in \u001b[0;36mDefaultRefineProgram.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m     83\u001b[0m         answer \u001b[39m=\u001b[39m answer\u001b[39m.\u001b[39mmodel_dump_json()\n\u001b[1;32m     84\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_llm\u001b[39m.\u001b[39;49mpredict(\n\u001b[1;32m     86\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prompt,\n\u001b[1;32m     87\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds,\n\u001b[1;32m     88\u001b[0m     )\n\u001b[1;32m     89\u001b[0m \u001b[39mreturn\u001b[39;00m StructuredRefineResponse(answer\u001b[39m=\u001b[39manswer, query_satisfied\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/llama_index_instrumentation/dispatcher.py:319\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m             _logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to reset active_span_id: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    320\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, asyncio\u001b[39m.\u001b[39mFuture):\n\u001b[1;32m    321\u001b[0m         \u001b[39m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         new_future \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/llama_index/core/llms/llm.py:641\u001b[0m, in \u001b[0;36mLLM.predict\u001b[0;34m(self, prompt, **prompt_args)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata\u001b[39m.\u001b[39mis_chat_model:\n\u001b[1;32m    640\u001b[0m     messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_messages(prompt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprompt_args)\n\u001b[0;32m--> 641\u001b[0m     chat_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat(messages)\n\u001b[1;32m    642\u001b[0m     output \u001b[39m=\u001b[39m chat_response\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    643\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/llama_index_instrumentation/dispatcher.py:319\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m             _logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to reset active_span_id: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    320\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, asyncio\u001b[39m.\u001b[39mFuture):\n\u001b[1;32m    321\u001b[0m         \u001b[39m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         new_future \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/llama_index/core/llms/callbacks.py:175\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[0;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m event_id \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_event_start(\n\u001b[1;32m    167\u001b[0m     CBEventType\u001b[39m.\u001b[39mLLM,\n\u001b[1;32m    168\u001b[0m     payload\u001b[39m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m     },\n\u001b[1;32m    173\u001b[0m )\n\u001b[1;32m    174\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     f_return_val \u001b[39m=\u001b[39m f(_self, messages, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    176\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    177\u001b[0m     callback_manager\u001b[39m.\u001b[39mon_event_end(\n\u001b[1;32m    178\u001b[0m         CBEventType\u001b[39m.\u001b[39mLLM,\n\u001b[1;32m    179\u001b[0m         payload\u001b[39m=\u001b[39m{EventPayload\u001b[39m.\u001b[39mEXCEPTION: e},\n\u001b[1;32m    180\u001b[0m         event_id\u001b[39m=\u001b[39mevent_id,\n\u001b[1;32m    181\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/llama_index/llms/openai/base.py:386\u001b[0m, in \u001b[0;36mOpenAI.chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     chat_fn \u001b[39m=\u001b[39m completion_to_chat_decorator(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_complete)\n\u001b[0;32m--> 386\u001b[0m \u001b[39mreturn\u001b[39;00m chat_fn(messages, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/llama_index/llms/openai/base.py:112\u001b[0m, in \u001b[0;36mllm_retry_decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    105\u001b[0m retry \u001b[39m=\u001b[39m create_retry_decorator(\n\u001b[1;32m    106\u001b[0m     max_retries\u001b[39m=\u001b[39mmax_retries,\n\u001b[1;32m    107\u001b[0m     random_exponential\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m     max_seconds\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m,\n\u001b[1;32m    111\u001b[0m )\n\u001b[0;32m--> 112\u001b[0m \u001b[39mreturn\u001b[39;00m retry(f)(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/tenacity/__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m copy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    335\u001b[0m wrapped_f\u001b[39m.\u001b[39mstatistics \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mstatistics  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m \u001b[39mreturn\u001b[39;00m copy(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/tenacity/__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    474\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    476\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[39mfor\u001b[39;00m action \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter_state\u001b[39m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[39m=\u001b[39m action(retry_state)\n\u001b[1;32m    377\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/tenacity/__init__.py:418\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m retry_exc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    417\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[0;32m--> 418\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m    419\u001b[0m \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/tenacity/__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mreraise\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mNoReturn:\n\u001b[1;32m    184\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_attempt\u001b[39m.\u001b[39mfailed:\n\u001b[0;32m--> 185\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlast_attempt\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    186\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/tenacity/__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    479\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/llama_index/llms/openai/base.py:482\u001b[0m, in \u001b[0;36mOpenAI._chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m message_dicts \u001b[39m=\u001b[39m to_openai_message_dicts(\n\u001b[1;32m    477\u001b[0m     messages,\n\u001b[1;32m    478\u001b[0m     model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel,\n\u001b[1;32m    479\u001b[0m )\n\u001b[1;32m    481\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreuse_client:\n\u001b[0;32m--> 482\u001b[0m     response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mchat\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m    483\u001b[0m         messages\u001b[39m=\u001b[39;49mmessage_dicts,\n\u001b[1;32m    484\u001b[0m         stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    485\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_model_kwargs(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs),\n\u001b[1;32m    486\u001b[0m     )\n\u001b[1;32m    487\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[39mwith\u001b[39;00m client:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/openai/_utils/_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 287\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:925\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    883\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcreate\u001b[39m(\n\u001b[1;32m    884\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    922\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    923\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    924\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 925\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    926\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    927\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[1;32m    928\u001b[0m             {\n\u001b[1;32m    929\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: messages,\n\u001b[1;32m    930\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[1;32m    931\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39maudio\u001b[39;49m\u001b[39m\"\u001b[39;49m: audio,\n\u001b[1;32m    932\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[1;32m    933\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_call,\n\u001b[1;32m    934\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: functions,\n\u001b[1;32m    935\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[1;32m    936\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: logprobs,\n\u001b[1;32m    937\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_completion_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_completion_tokens,\n\u001b[1;32m    938\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[1;32m    939\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m: metadata,\n\u001b[1;32m    940\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodalities\u001b[39;49m\u001b[39m\"\u001b[39;49m: modalities,\n\u001b[1;32m    941\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[1;32m    942\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mparallel_tool_calls\u001b[39;49m\u001b[39m\"\u001b[39;49m: parallel_tool_calls,\n\u001b[1;32m    943\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mprediction\u001b[39;49m\u001b[39m\"\u001b[39;49m: prediction,\n\u001b[1;32m    944\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[1;32m    945\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mreasoning_effort\u001b[39;49m\u001b[39m\"\u001b[39;49m: reasoning_effort,\n\u001b[1;32m    946\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mresponse_format\u001b[39;49m\u001b[39m\"\u001b[39;49m: response_format,\n\u001b[1;32m    947\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[1;32m    948\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mservice_tier\u001b[39;49m\u001b[39m\"\u001b[39;49m: service_tier,\n\u001b[1;32m    949\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[1;32m    950\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstore\u001b[39;49m\u001b[39m\"\u001b[39;49m: store,\n\u001b[1;32m    951\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[1;32m    952\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream_options\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream_options,\n\u001b[1;32m    953\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[1;32m    954\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtool_choice\u001b[39;49m\u001b[39m\"\u001b[39;49m: tool_choice,\n\u001b[1;32m    955\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtools\u001b[39;49m\u001b[39m\"\u001b[39;49m: tools,\n\u001b[1;32m    956\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_logprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_logprobs,\n\u001b[1;32m    957\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[1;32m    958\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[1;32m    959\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mweb_search_options\u001b[39;49m\u001b[39m\"\u001b[39;49m: web_search_options,\n\u001b[1;32m    960\u001b[0m             },\n\u001b[1;32m    961\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParamsStreaming\n\u001b[1;32m    962\u001b[0m             \u001b[39mif\u001b[39;49;00m stream\n\u001b[1;32m    963\u001b[0m             \u001b[39melse\u001b[39;49;00m completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParamsNonStreaming,\n\u001b[1;32m    964\u001b[0m         ),\n\u001b[1;32m    965\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    966\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    967\u001b[0m         ),\n\u001b[1;32m    968\u001b[0m         cast_to\u001b[39m=\u001b[39;49mChatCompletion,\n\u001b[1;32m    969\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    970\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[ChatCompletionChunk],\n\u001b[1;32m    971\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/openai/_base_client.py:1249\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mpost\u001b[39m(\n\u001b[1;32m   1236\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1237\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1244\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1245\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1246\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1247\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1248\u001b[0m     )\n\u001b[0;32m-> 1249\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_env/lib/python3.10/site-packages/openai/_base_client.py:1004\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRaising connection error\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1004\u001b[0m     \u001b[39mraise\u001b[39;00m APIConnectionError(request\u001b[39m=\u001b[39mrequest) \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39merr\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m log\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m   1007\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mHTTP Response: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1008\u001b[0m     request\u001b[39m.\u001b[39mmethod,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     response\u001b[39m.\u001b[39mheaders,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[1;32m   1014\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mrequest_id: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, response\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mx-request-id\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m: Connection error."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "QUERY =  'How do you ensure software compliance (licensing) in an organization '\n",
    "result = index.as_query_engine(llm=llm).query(QUERY)\n",
    "print(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\")\n",
    "display([(n.text, n.metadata) for n in result.source_nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "QUERY =  'How old was albert einstein when he died?'\n",
    "result = index.as_query_engine(llm=GEN_MODEL).query(QUERY)\n",
    "print(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\")\n",
    "display([(n.text, n.metadata) for n in result.source_nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
